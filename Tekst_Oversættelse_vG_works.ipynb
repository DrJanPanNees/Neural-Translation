{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tekst_Oversættelse_vG-works.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SL8z7NIUPts",
        "colab_type": "code",
        "outputId": "4e5dbaef-f87f-479a-b6d4-8b500a5f6aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymgFwzq9h0Lz",
        "colab_type": "code",
        "outputId": "2ba0c6d7-2848-479f-d9d6-847db7ed7a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Crach COLAB to get more RAM\n",
        "'''\n",
        "d=[]\n",
        "while(1):\n",
        "  d.append('1')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nd=[]\\nwhile(1):\\n  d.append('1')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oOTqSJEvOjq8",
        "outputId": "99384afc-d9a4-461b-a3a0-50f8b6a02c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#================== Copy Rights ==================\n",
        "print('='*100)\n",
        "print('Copy rights: Dr. Jan P. Nees, PhD.')\n",
        "print('='*100)\n",
        "#================== Import libraries ==================\n",
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "#tf.executing_eagerly()\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "#from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam, adam\n",
        "#from keras.losses import sparse_categorical_crossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import plot_model\n",
        "from keras.models import load_model\n",
        "import unicodedata\n",
        "import re\n",
        "import io\n",
        "from keras import Sequential\n",
        "from keras.layers import GRU, RepeatVector, TimeDistributed, Dense, LSTM, Input\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#================== Methods ==================\n",
        "\n",
        "#---------Tokenizer Method -----------------------------------\n",
        "# ------ Main issues: Not sure if it does it correctly to DK and DE sentences. --------\n",
        "\n",
        "def pad(x, length=106):\n",
        "    #print('Padding version 1')\n",
        "    if length is None:\n",
        "        length = max([len(sentence) for sentence in x])\n",
        "    return pad_sequences(x, maxlen = length, padding = 'post')\n",
        "\n",
        "\n",
        "def tokenize(x): # code from:\n",
        "    from keras.preprocessing.text import Tokenizer\n",
        "    x_tk = Tokenizer(num_words=500)\n",
        "    x_tk.fit_on_texts(x)\n",
        "    return x_tk.texts_to_sequences(x), x_tk\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    Load dataset\n",
        "    \"\"\"\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    return data.split('\\n')\n",
        "\n",
        "#================== ======================================== ==================\n",
        "#english_reader = load_data('europarl-v8.en')\n",
        "#danish_reader = load_data('europarl-v8.da')\n",
        "\n",
        "print('Dataset Loaded')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Copy rights: Dr. Jan P. Nees, PhD.\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neqsMhQhbANo",
        "colab_type": "code",
        "outputId": "4386a280-727b-412b-97c9-92581c325aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "versionTF = tf.__version__\n",
        "\n",
        "if versionTF != '2.0.0':\n",
        "  !pip install tensorflow==2.0.0\n",
        "else:\n",
        "  print(versionTF)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGnZl7230XUy",
        "colab_type": "code",
        "outputId": "0de6b8be-6fe9-4dac-ea72-5d5310bf2af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    #w = re.sub(r\"[å]+\", \"aa\", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def load_data_v2(path):\n",
        "    \n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    #w = preprocess_sentence(line) for line in lines\n",
        "    #return w\n",
        "    w = [preprocess_sentence(line)  for line in lines[:8000]] #<----------- How many lines of sentences\n",
        "        #print(w)\n",
        "            #data = preprocess_sentence(lines)\n",
        "            #preprocess_sentence(data) \n",
        "\n",
        "    return w\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "print(\"\"\"\n",
        "Models has been loaded\n",
        "Methods has been loaded\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Models has been loaded\n",
            "Methods has been loaded\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfMYiWcq0XVA",
        "colab_type": "code",
        "outputId": "88912717-d384-486a-b020-442c6ed31b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "english_reader = load_data_v2('drive/My Drive/txt/europarl-v7.da-en.en')\n",
        "danish_reader = load_data_v2('drive/My Drive/txt/europarl-v7.da-en.da')\n",
        "\n",
        "print('Load finished')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkWkecjU0XVI",
        "colab_type": "code",
        "outputId": "c0dfabf0-a37e-4285-865f-241bc02a0f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(english_reader[1])\n",
        "print(danish_reader[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> i declare resumed the session of the european parliament adjourned on friday december , and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period . <end>\n",
            "<start> jeg erklaerer europa parlamentets session , der blev afbrudt fredag den . december , for genoptaget . endnu en gang vil jeg oenske dem godt nytaar , og jeg haaber , de har haft en god ferie . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kkB1KRx0XVO",
        "colab_type": "code",
        "outputId": "3165f9da-8ae8-4cd3-e67e-46af34969baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "print('tokenizer loaded')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizer loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "magPYK5n0XVT",
        "colab_type": "code",
        "outputId": "99093cd9-d357-4cd9-bb45-90c51785b22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "target_tensor, targ_lang = tokenize(english_reader)\n",
        "input_tensor, inp_lang = tokenize(danish_reader)\n",
        "\n",
        "print('target_tensor.shape: ', target_tensor.shape)\n",
        "print('input_tensor.shape: ', input_tensor.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target_tensor.shape:  (8000, 143)\n",
            "input_tensor.shape:  (8000, 146)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqCDJzoR0XVW",
        "colab_type": "code",
        "outputId": "2228fb73-bbbd-4d9b-de11-8de5fea118db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6400 6400 1600 1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDtfr_rX0XVa",
        "colab_type": "code",
        "outputId": "1109a477-a626-4a42-9903-990b1a1844ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "    \n",
        "print('Model loaded')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtWjznoB0XVg",
        "colab_type": "code",
        "outputId": "544ad5ba-2c1c-43c6-9bb8-7a942daf1803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[1])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "3 ----> <start>\n",
            "8 ----> det\n",
            "9 ----> er\n",
            "59 ----> derfor\n",
            "1993 ----> udelukket\n",
            "1 ----> ,\n",
            "5 ----> at\n",
            "39 ----> europa\n",
            "42 ----> parlamentet\n",
            "169 ----> faar\n",
            "170 ----> nogen\n",
            "6922 ----> formel\n",
            "972 ----> indflydelse\n",
            "20 ----> paa\n",
            "12844 ----> forhandlingsprocessen\n",
            "51 ----> eller\n",
            "40 ----> ved\n",
            "4463 ----> ratificeringen\n",
            "2 ----> .\n",
            "4 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "3 ----> <start>\n",
            "18 ----> it\n",
            "11 ----> is\n",
            "79 ----> therefore\n",
            "95 ----> out\n",
            "6 ----> of\n",
            "1 ----> the\n",
            "108 ----> question\n",
            "12 ----> that\n",
            "1 ----> the\n",
            "28 ----> european\n",
            "41 ----> parliament\n",
            "39 ----> should\n",
            "17 ----> be\n",
            "203 ----> given\n",
            "93 ----> any\n",
            "2042 ----> formal\n",
            "1498 ----> influence\n",
            "209 ----> over\n",
            "1 ----> the\n",
            "2230 ----> negotiation\n",
            "184 ----> process\n",
            "53 ----> or\n",
            "209 ----> over\n",
            "8554 ----> ratification\n",
            "5 ----> .\n",
            "4 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YDQ9zNeit25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#=============================================================================\n",
        "#================= TEXT ANALYSIS HERE ========================================\n",
        "#=============================================================================\n",
        "\n",
        "#------------- DATA processing-----------------\n",
        "print('------- Data processing -------------')\n",
        "english_words_counter = collections.Counter([word for sentence in english_reader for word in sentence.split()])\n",
        "french_words_counter = collections.Counter([word for sentence in danish_reader for word in sentence.split()])\n",
        "print('{} English words.'.format(len([word for sentence in english_reader for word in sentence.split()])))\n",
        "print('{} unique English words.'.format(len(english_words_counter)))\n",
        "print('20 Most common words in the English dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(20)))[0]) + '\"')\n",
        "print()\n",
        "print('{} French words.'.format(len([word for sentence in danish_reader for word in sentence.split()])))\n",
        "print('{} unique French words.'.format(len(french_words_counter)))\n",
        "print('20 Most common words in the French dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(20)))[0]) + '\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEmMDOnRebXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#=============================================================================\n",
        "#================= INSERT OWN NN HERE ========================================\n",
        "#=============================================================================\n",
        "\n",
        "import time\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE41JwJI0XVi",
        "colab_type": "code",
        "outputId": "9a92c012-55ad-49e1-e87d-46662d766589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#---------- Deep learning starts --------\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print('Deep learning model pre-modelling finished')\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape\n",
        "\n",
        "print('--------- Deep Learning tensorflow begins ---------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deep learning model pre-modelling finished\n",
            "<BatchDataset shapes: ((64, 146), (64, 143)), types: (tf.int32, tf.int32)>\n",
            "--------- Deep Learning tensorflow begins ---------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YK0RvkZ0XVl",
        "colab_type": "code",
        "outputId": "1ab415fb-8f9a-4b62-c172-378f497dfa07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 146, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b6VT3E2zPhJ0",
        "outputId": "207a9121-4768-466c-a769-cfe57cb140a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 146, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9-BBKWx0XVv",
        "colab_type": "code",
        "outputId": "3a1de75a-e9cb-4700-ca83-766b888ed885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 9306)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9HadPp70XVx",
        "colab_type": "code",
        "outputId": "816d1d68-c606-4905-8c7f-4ab2d76aaf8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "print('Method build finished')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Method build finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-4GY5pe0XV0",
        "colab_type": "code",
        "outputId": "b6fe7179-f6ea-413c-eff2-3f6edd7c74b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import time\n",
        "\n",
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.7394\n",
            "Epoch 1 Loss 1.2571\n",
            "Time taken for 1 epoch 12626.807191371918 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO-xIC2N0XV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsMQC-Uw0XV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ery6cTe0XV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giCUbjmx0XV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTFKNNLY0XV8",
        "colab_type": "code",
        "outputId": "ec99a086-b367-4cae-cf26-37487d8f4193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f1b0c51eb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFBK1c790XV9",
        "colab_type": "code",
        "outputId": "b58d7c92-0e86-4d74-afd2-fe5813dd118c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        }
      },
      "source": [
        "translate('hvorfor er der ingen brandinstrukser.')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hvorfor er der ingen brandinstrukser . <end>\n",
            "Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAE8AAAKqCAYAAAB7IgOeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OysLp2NN0XV_",
        "colab_type": "code",
        "outputId": "9b7ed3bd-e712-4559-dc7a-a22877731266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        }
      },
      "source": [
        "translate('hvor er EU')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hvor er eu <end>\n",
            "Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAAJzCAYAAAC287WOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-rddUto0XWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}